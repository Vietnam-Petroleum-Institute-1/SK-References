{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAITextCompletion, OpenAITextEmbedding\n",
    "#load .env\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Define kernel\n",
    "kernel = sk.Kernel()\n",
    "# Define services\n",
    "api_key, org_id = sk.openai_settings_from_dot_env()\n",
    "## Add OPENAI service to kernel\n",
    "kernel.add_text_completion_service(\"dv\", OpenAITextCompletion(\"text-davinci-003\", api_key, org_id))\n",
    "kernel.add_text_embedding_generation_service(\"ada\", OpenAITextEmbedding(\"text-embedding-ada-002\", api_key, org_id))\n",
    "## Add memory store\n",
    "kernel.register_memory_store(memory_store=sk.memory.VolatileMemoryStore())\n",
    "kernel.import_skill(sk.core_skills.TextMemorySkill())\n",
    "\n",
    "# Manually adding memories\n",
    "await kernel.memory.save_information_async(\n",
    "        collection=\"aboutMe\", id=\"info1\", text=\"My name is Andrea\"\n",
    "    )\n",
    "\n",
    "# Search for memories\n",
    "question = \"what's my name\"\n",
    "result = await kernel.memory.search_async(collection=\"aboutMe\", \n",
    "                                          query=question, \n",
    "                                          limit=1, \n",
    "                                          min_relevance_score=0.7\n",
    "                                          )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic Kernel Chat History\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "async def setup_chat_with_memory(\n",
    "    kernel: sk.Kernel,\n",
    ") -> Tuple[sk.SKFunctionBase, sk.SKContext]:\n",
    "    sk_prompt = \"\"\"\n",
    "    ChatBot can have a conversation with you about any topic.\n",
    "    It can give explicit instructions or say 'I don't know' if\n",
    "    it does not have an answer.\n",
    "\n",
    "    Information about me, from previous conversations:\n",
    "    - {{$fact1}} {{recall $fact1}}\n",
    "\n",
    "    Chat:\n",
    "    {{$chat_history}}\n",
    "    User: {{$user_input}}\n",
    "    ChatBot: \"\"\".strip()\n",
    "    ## Create Semantic Function Chat\n",
    "    chat_func = kernel.create_semantic_function(sk_prompt, max_tokens=200, temperature=0.8)\n",
    "    ## Create SKContext\n",
    "    context = kernel.create_new_context()\n",
    "    \n",
    "    context[\"fact1\"] = \"what is my name?\"\n",
    "    context[sk.core_skills.TextMemorySkill.COLLECTION_PARAM] = \"aboutMe\"\n",
    "    context[sk.core_skills.TextMemorySkill.RELEVANCE_PARAM] = 0.8\n",
    "    \n",
    "    ## Create chat history variable\n",
    "    context[\"chat_history\"] = \"\"\n",
    "\n",
    "    return chat_func, context\n",
    "    \n",
    "async def chat(\n",
    "    kernel: sk.Kernel, chat_func: sk.SKFunctionBase, context: sk.SKContext\n",
    ") -> bool:\n",
    "    try:\n",
    "        user_input = input(\"User:> \")\n",
    "        context[\"user_input\"] = user_input\n",
    "        print(f\"User:> {user_input}\")\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\nExiting chat...\")\n",
    "        return False\n",
    "    except EOFError:\n",
    "        print(\"\\n\\nExiting chat...\")\n",
    "        return False\n",
    "\n",
    "    if user_input == \"exit\":\n",
    "        print(\"\\n\\nExiting chat...\")\n",
    "        return False\n",
    "    ## Run chat function\n",
    "    answer = await kernel.run_async(chat_func, input_vars=context.variables)\n",
    "    ## Save chat history\n",
    "    context[\"chat_history\"] += f\"\\nUser:> {user_input}\\nChatBot:> {answer}\\n\"\n",
    "\n",
    "    print(f\"ChatBot:> {answer}\")\n",
    "    return True\n",
    "\n",
    "print(\"Setting up a chat (with memory!)\")\n",
    "chat_func, context = await setup_chat_with_memory(kernel)\n",
    "\n",
    "print(\"Begin chatting (type 'exit' to exit):\\n\")\n",
    "chatting = True\n",
    "while chatting:\n",
    "    chatting = await chat(kernel, chat_func, context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding documents to your memory\n",
    "\n",
    "Many times in your applications you'll want to bring in external documents into your memory. Let's see how we can do this using our VolatileMemoryStore.\n",
    "\n",
    "Let's first get some data using some of the links in the Semantic Kernel repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define documents\n",
    "github_files ={}\n",
    "github_files[\"https://github.com/microsoft/semantic-kernel/blob/main/README.md\"] = \\\n",
    "    \"README: Installation, getting started, and how to contribute\"\n",
    "github_files[\"https://github.com/microsoft/semantic-kernel/blob/main/samples/notebooks/dotnet/02-running-prompts-from-file.ipynb\"] = \\\n",
    "    \"Jupyter notebook describing how to pass prompts from a file to a semantic skill or function\"\n",
    "github_files[\"https://github.com/microsoft/semantic-kernel/blob/main/samples/notebooks/dotnet/00-getting-started.ipynb\"] = \\\n",
    "    \"Jupyter notebook describing how to get started with the Semantic Kernel\"\n",
    "github_files[\"https://github.com/microsoft/semantic-kernel/tree/main/samples/skills/ChatSkill/ChatGPT\"] = \\\n",
    "    \"Sample demonstrating how to create a chat skill interfacing with ChatGPT\"\n",
    "github_files[\"https://github.com/microsoft/semantic-kernel/blob/main/dotnet/src/SemanticKernel/Memory/Volatile/VolatileMemoryStore.cs\"] = \\\n",
    "    \"C# class that defines a volatile embedding store\"\n",
    "github_files[\"https://github.com/microsoft/semantic-kernel/tree/main/samples/dotnet/KernelHttpServer/README.md\"] = \\\n",
    "    \"README: How to set up a Semantic Kernel Service API using Azure Function Runtime v4\"\n",
    "github_files[\"https://github.com/microsoft/semantic-kernel/tree/main/samples/apps/chat-summary-webapp-react/README.md\"] = \\\n",
    "    \"README: README associated with a sample starter react-based chat summary webapp\"\n",
    "\n",
    "# Crearte a memory collection\n",
    "memory_collection_name = \"SKGitHub\"\n",
    "print(\"Adding some GitHub file URLs and their descriptions to a volatile Semantic Memory.\")\n",
    "i = 0\n",
    "# Add documents to memory\n",
    "for entry, value in github_files.items():\n",
    "    await kernel.memory.save_reference_async(\n",
    "        collection=memory_collection_name,\n",
    "        description=value,\n",
    "        text=value,\n",
    "        external_id=entry,\n",
    "        external_source_name=\"GitHub\"\n",
    "    )\n",
    "    i += 1\n",
    "    print(\"  URL {} saved\".format(i))\n",
    "\n",
    "# Query information from memory\n",
    "ask = \"I love Jupyter notebooks, how should I get started?\"\n",
    "print(\"===========================\\n\" + \"Query: \" + ask + \"\\n\")\n",
    "## Search\n",
    "memories = await kernel.memory.search_async(collection=memory_collection_name, \n",
    "                                            query=ask, \n",
    "                                            limit=5, \n",
    "                                            min_relevance_score=0.77\n",
    "                                            )\n",
    "## Print search results\n",
    "i = 0\n",
    "for memory in memories:\n",
    "    i += 1\n",
    "    print(f\"Result {i}:\")\n",
    "    print(\"  URL:     : \" + memory.id)\n",
    "    print(\"  Title    : \" + memory.description)\n",
    "    print(\"  Relevance: \" + str(memory.relevance))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "booksage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
