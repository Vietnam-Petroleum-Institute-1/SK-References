{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai, random, os\n",
    "from qdrant_client import QdrantClient\n",
    "from qna import responding_openai\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize OpenAI API\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "# Define QdrantClient CONGDOAN\n",
    "os.environ['QDRANT_URL'] = \"https://bd26be9e-256b-4c84-85b3-2588bfdd284e.us-east-1-0.aws.cloud.qdrant.io:6333\"\n",
    "os.environ['QDRANT_API_KEY'] = 'UiPqMg7pMhRsJ6_41vfskxzZZzlEwtWbgu3NOBxhOsEQsaIlX3vQdw'\n",
    "os.environ['QDRANT_COLLECTION_NAME'] = 'context'\n",
    "\n",
    "qdrant_client = QdrantClient(url=os.environ['QDRANT_URL'], api_key=os.environ['QDRANT_API_KEY'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG (Conventional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Openai Embedding a text to vector\n",
    "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "   text = text.replace(\"\\n\", \" \")\n",
    "   return openai.Embedding.create(input = [text], model=model)['data'][0]['embedding']\n",
    "# Search Qdrant Docs\n",
    "def search_qdrant(query, top_k=3):\n",
    "    search_result = qdrant_client.search(\n",
    "        collection_name=os.environ['QDRANT_COLLECTION_NAME'],\n",
    "        query_vector=get_embedding(query),\n",
    "        limit=top_k\n",
    "    )\n",
    "    score_dict =  {result.payload['page_content']: result.score for result in search_result}\n",
    "    return search_result, score_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Querying\n",
    "query = \"Nêu các nhiệm vụ, quyền hạn của công đoàn cơ sở?\"\n",
    "# Get relevant documents\n",
    "unranked_search_result, unranked_score_dict = search_qdrant(query)\n",
    "# Re-arrange the received documents\n",
    "search_info = \"\\n\\n\".join(unranked_search_result[i].payload['page_content'] for i in range(len(unranked_search_result)))\n",
    "# Generate response with OpenAI\n",
    "results, chatgpt_response_time = responding_openai(query, search_info)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG Fusion\n",
    "Adding some steps below:\n",
    "- Create multiple simple questions from the raw query\n",
    "- Semantic Search (Vector) with each sub-queries\n",
    "- Re-ranking with RRF (Reciprocal Rank Fusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate queries using OpenAI's ChatGPT\n",
    "def generate_queries_chatgpt(original_query):\n",
    "    system_role = \"You are a helpful assistant that generates multiple search queries based on a single input query.\"\n",
    "    user_prompt = f\"Generate multiple search queries in Vietnamese related to: {original_query}\"\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_role},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "            {\"role\": \"user\", \"content\": \"OUTPUT (4 Vietnamese queries):\"}\n",
    "        ]\n",
    "    )\n",
    "    generated_queries = response.choices[0][\"message\"][\"content\"].strip().split(\"\\n\")\n",
    "    return generated_queries\n",
    "\n",
    "# Reciprocal Rank Fusion algorithm\n",
    "def reciprocal_rank_fusion(search_results_dict, k=60):\n",
    "    fused_scores = {}\n",
    "    print(\"Initial individual search result ranks:\")\n",
    "    for query, doc_scores in search_results_dict.items():\n",
    "        print(f\"For query '{query}': {doc_scores}\")\n",
    "        \n",
    "    for query, doc_scores in search_results_dict.items():\n",
    "        for rank, (doc, score) in enumerate(sorted(doc_scores.items(), key=lambda x: x[1], reverse=True)):\n",
    "            if doc not in fused_scores:\n",
    "                fused_scores[doc] = 0\n",
    "            previous_score = fused_scores[doc]\n",
    "            fused_scores[doc] += 1 / (rank + k)\n",
    "            # print(f\"Updating score for {doc} from {previous_score} to {fused_scores[doc]} based on rank {rank} in query '{query}'\")\n",
    "\n",
    "    reranked_results = {doc: score for doc, score in sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)}\n",
    "    print(\"-----------------------------------\")\n",
    "    print(\"Final reranked results:\", reranked_results)\n",
    "    print(\"-----------------------------------\")\n",
    "    return reranked_results\n",
    "\n",
    "# Dummy function to simulate generative output\n",
    "def generate_output(reranked_results, queries):\n",
    "    return f\"Final output based on {queries} and reranked documents: {list(reranked_results.keys())}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original query\n",
    "original_query = \"Nêu các nhiệm vụ, quyền hạn của công đoàn cơ sở?\"\n",
    "# Top_k results\n",
    "top_k = 3\n",
    "# Generate sub-questions from original query\n",
    "generated_queries = generate_queries_chatgpt(original_query)\n",
    "# Search Qdrant for each generated query\n",
    "all_results = {}\n",
    "for query in generated_queries:\n",
    "    search_results, score_dict = search_qdrant(query)\n",
    "    all_results[query] = score_dict\n",
    "# Rerank the results\n",
    "reranked_results = reciprocal_rank_fusion(all_results)\n",
    "# Convert reraned info to a string\n",
    "reranked_context = list(reranked_results.keys())\n",
    "search_info_rerank = \"\\n\\n\".join(reranked_context[i] for i in range(top_k))\n",
    "# Generate response with OpenAI\n",
    "results, chatgpt_response_time = responding_openai(original_query, search_info_rerank)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "booksage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
