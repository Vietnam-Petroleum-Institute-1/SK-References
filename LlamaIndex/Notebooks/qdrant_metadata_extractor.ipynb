{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cohere\n",
    "from llama_index.llms import OpenAI\n",
    "import openai, nest_asyncio, warnings\n",
    "from qdrant_client.http import models\n",
    "from qdrant_client import QdrantClient\n",
    "from llama_index.node_parser import SimpleNodeParser\n",
    "from llama_index.text_splitter import TokenTextSplitter\n",
    "from llama_index import VectorStoreIndex, ServiceContext, SimpleDirectoryReader\n",
    "from llama_index.node_parser.extractors import (\n",
    "    MetadataExtractor,\n",
    "    SummaryExtractor,\n",
    "    QuestionsAnsweredExtractor,\n",
    "    TitleExtractor,\n",
    "    KeywordExtractor,\n",
    ")\n",
    "\n",
    "def metadata_creator(llm, loaded_doc, separator:str=\"\\n\\n\", chunk_size:int=1024, chunk_overlap:int=128):\n",
    "    TITLE_NODE_TEMPLATE = \"\"\"\\\n",
    "    Context: {context_str}. Give a title that summarizes all of \\\n",
    "    the unique entities, titles or themes found in the context in Vietnamese. Title: \"\"\"\n",
    "    TITLE_COMBINE_TEMPLATE = \"\"\"\\\n",
    "    {context_str}. Based on the above candidate titles and content, \\\n",
    "    what is the comprehensive title for this document? Answer in Vietnamese. Title: \"\"\"\n",
    "    QAE_TEMPLATE = f\"\"\"\\\n",
    "    {{context_str}}. Given the contextual information, \\\n",
    "    generate 5 questions this document can provide \\\n",
    "    specific answers in Vietnamese to which are unlikely to be found elsewhere: \\\n",
    "    \"\"\"\n",
    "    SUMMARY_EXTRACT_TEMPLATE = \"\"\"\\\n",
    "    Here is the content of the section: {context_str}. \\\n",
    "    Summarize the key topics and entities of the section in Vietnamese. Summary: \"\"\"\n",
    "\n",
    "    metadata_extractor = MetadataExtractor(\n",
    "        extractors=[\n",
    "            TitleExtractor(nodes=3, \n",
    "                        llm=llm,\n",
    "                        node_template=TITLE_NODE_TEMPLATE,\n",
    "                        combine_template=TITLE_COMBINE_TEMPLATE,\n",
    "                        ),\n",
    "            QuestionsAnsweredExtractor(questions=3, \n",
    "                                    llm=llm,\n",
    "                                    prompt_template = QAE_TEMPLATE,\n",
    "                                    ),\n",
    "            SummaryExtractor(summaries=[\"self\"], #[\"prev\", \"self\", \"next\"]\n",
    "                            llm=llm,\n",
    "                            prompt_template=SUMMARY_EXTRACT_TEMPLATE,\n",
    "                            ),\n",
    "            KeywordExtractor(keywords=5, llm=llm),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    text_splitter = TokenTextSplitter(separator=separator, \n",
    "                                      chunk_size=chunk_size, \n",
    "                                      chunk_overlap=chunk_overlap)\n",
    "    node_parser = SimpleNodeParser(\n",
    "        text_splitter=text_splitter,\n",
    "        metadata_extractor=metadata_extractor,\n",
    "    )\n",
    "    service_context = ServiceContext.from_defaults(llm=llm, node_parser=node_parser)\n",
    "    index = VectorStoreIndex.from_documents(\n",
    "        documents=loaded_doc,\n",
    "        service_context=service_context,\n",
    "        show_progress=True,\n",
    "    )\n",
    "    return index\n",
    "\n",
    "def qdrant_collection_def(qdrant_url, qdrant_api_key, qdrant_collection, embedding_dim):\n",
    "    client = QdrantClient(url=qdrant_url, api_key=qdrant_api_key)\n",
    "    try:\n",
    "        client.create_collection(\n",
    "            collection_name=qdrant_collection,\n",
    "            vectors_config=models.VectorParams(size=embedding_dim, distance=models.Distance.COSINE),\n",
    "        )\n",
    "    except:\n",
    "        pass\n",
    "    return client\n",
    "\n",
    "def vectorizer(model:str='openai', embedding_text:str=None):\n",
    "    if model == 'openai':\n",
    "        embedding_vector = openai.Embedding.create(\n",
    "                                input = embedding_text,\n",
    "                                model=\"text-embedding-ada-002\",\n",
    "                                )['data'][0]['embedding']\n",
    "        return embedding_vector\n",
    "    if model == 'cohere':\n",
    "        co = cohere.Client(os.environ['COHERE_API_KEY'])\n",
    "        embedding_vector = co.embed(\n",
    "                            texts=[embedding_text],\n",
    "                            model='multilingual-22-12',\n",
    "                            )\n",
    "        return embedding_vector\n",
    "    \n",
    "def qdrant_uploader(client, embedding_model, qdrant_collection, docs):\n",
    "    points=[]\n",
    "    for k, doc in docs.items():\n",
    "        id = k\n",
    "        embedding_text = doc.metadata['document_title'] + \"\\n\" +\\\n",
    "                        doc.get_content().replace(\"\\n\\n\", \"\\n\") + \"\\n\" +\\\n",
    "                        doc.metadata['questions_this_excerpt_can_answer']\n",
    "        point = models.PointStruct(\n",
    "                id=id,\n",
    "                vector=vectorizer(model=embedding_model, embedding_text=embedding_text),\n",
    "                payload={\n",
    "                    \"page_content\": doc.get_content(),\n",
    "                    \"file_name\": doc.metadata['file_name'],\n",
    "                    \"document_title\": doc.metadata['document_title'],\n",
    "                    \"section_summary\": doc.metadata['section_summary'],\n",
    "                    # \"prev_section_summary\": doc.metadata['prev_section_summary'],\n",
    "                    # \"next_section_summary\": doc.metadata['next_section_summary'],\n",
    "                    \"excerpt_keywords\": doc.metadata['excerpt_keywords'],\n",
    "                    \"questions\": doc.metadata['questions_this_excerpt_can_answer'],\n",
    "                },\n",
    "            )\n",
    "        points.append(point)\n",
    "        print(f\"Processing Document ID: {id}, File Name: {doc.metadata['file_name']}\")\n",
    "    client.upsert(collection_name=qdrant_collection, points=points)\n",
    "    print(\"Qdrant Upserting Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "294af41cc8ca4c68b7384f1f9a14d1d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing documents into nodes:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cb36eec3fe3489191220f7300ae5232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting questions:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "780a1f8129ca4094952d9566c01c909d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ecc18d53f2f4bb6821f08eaa26bc10b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Document ID: b0af3306-be3d-433c-8f9c-cf21ff913982, File Name: bachlongvi_text copy.docx\n",
      "Qdrant Upserting Finished!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf4c33719d8748d685884ff852927cff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing documents into nodes:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0edae74d395747e9bb8cc7484a95ca87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting questions:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "682a43e004ed489fac5e3a0f6e3a7905",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01cbda3671734b38afcf6d295229bce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Document ID: 7f11f17c-1d0b-4c7c-9a21-cce85972a3bb, File Name: bachlongvi_text.docx\n",
      "Qdrant Upserting Finished!\n"
     ]
    }
   ],
   "source": [
    "# Disable all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Enable asyncio\n",
    "nest_asyncio.apply()\n",
    "# Set OpenAI API key\n",
    "openai.api_key = \"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\"\n",
    "# Set Qdrant API key\n",
    "qdrant_url=\"https://bd26be9e-256b-4c84-85b3-2588bfdd284e.us-east-1-0.aws.cloud.qdrant.io:6333\" #muito1712\n",
    "qdrant_api_key=\"qozq2_b5cqx0CI_EuDDWDUrTSEozbkQgCKplto5hlssNa064wwNKjg\"\n",
    "os.environ['COHERE_API_KEY'] = \"4ECOTqDXJpIYhxMQhUZxY12PPSqvgtYFclJm4Gnz\"\n",
    "\n",
    "qdrant_collection = \"metadata_demo\"\n",
    "embedding_model = \"openai\"\n",
    "\n",
    "if embedding_model == \"openai\":\n",
    "    embedding_dim = 1536\n",
    "elif embedding_model == \"cohere\":\n",
    "    embedding_dim = 768\n",
    "    \n",
    "\n",
    "# Note the uninformative document file name, which may be a common scenario in a production setting\n",
    "loaded_docs = SimpleDirectoryReader(input_dir=\"./data/blv_data\").load_data()\n",
    "# Set up ServiceContext inlude llm and node_parser\n",
    "llm = OpenAI(temperature=0.0, model=\"gpt-3.5-turbo\", max_tokens=2000)\n",
    "# Build index\n",
    "for loaded_doc in loaded_docs:\n",
    "    ## Indexing and metadata extraction\n",
    "    index = metadata_creator(llm=llm, loaded_doc=[loaded_doc])\n",
    "    ## Read documents\n",
    "    docs = index.docstore.docs\n",
    "    ## Transfer to Qdrant Point, vector with payload\n",
    "    qdrant_client = qdrant_collection_def(qdrant_url, qdrant_api_key, qdrant_collection, embedding_dim)\n",
    "    ## Upload to Qdrant\n",
    "    qdrant_uploader(qdrant_client, embedding_model, qdrant_collection, docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "booksage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
