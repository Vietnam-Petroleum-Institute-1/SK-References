
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Converting an Existing Training Loop &#8212; Ray 3.0.0.dev0</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="https://docs.ray.io/en/master/_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="https://docs.ray.io/en/master/_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="https://docs.ray.io/en/master/_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="https://docs.ray.io/en/master/_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="https://docs.ray.io/en/master/_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="https://docs.ray.io/en/master/_static/pygments.css" />
    <link rel="stylesheet" href="https://docs.ray.io/en/master/_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="https://docs.ray.io/en/master/_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="https://docs.ray.io/en/master/_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="https://docs.ray.io/en/master/_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="https://docs.ray.io/en/master/_static/autodoc_pydantic.css" />
    <link rel="stylesheet" type="text/css" href="https://docs.ray.io/en/master/_static/css/custom.css" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css" />
    <link rel="stylesheet" type="text/css" href="https://docs.ray.io/en/master/_static/css/termynal.css" />
    <link rel="stylesheet" type="text/css" href="https://docs.ray.io/en/master/_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="https://docs.ray.io/en/master/_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css" />
    <link rel="stylesheet" type="text/css" href="https://docs.ray.io/_/static/css/badge_only.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="https://docs.ray.io/en/master/_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="https://docs.ray.io/en/master/_static/documentation_options.js"></script>
    <script src="https://docs.ray.io/en/master/_static/jquery.js"></script>
    <script src="https://docs.ray.io/en/master/_static/underscore.js"></script>
    <script src="https://docs.ray.io/en/master/_static/doctools.js"></script>
    <script src="https://docs.ray.io/en/master/_static/clipboard.min.js"></script>
    <script src="https://docs.ray.io/en/master/_static/copybutton.js"></script>
    <script src="https://docs.ray.io/en/master/_static/js/versionwarning.js"></script>
    <script src="https://docs.ray.io/en/master/_static/togglebutton.js"></script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script>
    <script defer="defer" src="https://docs.ray.io/en/master/_static/js/docsearch.js"></script>
    <script defer="defer" src="https://docs.ray.io/en/master/_static/js/csat.js"></script>
    <script defer="defer" src="https://docs.ray.io/en/master/_static/js/termynal.js"></script>
    <script defer="defer" src="https://docs.ray.io/en/master/_static/js/custom.js"></script>
    <script defer="defer" src="https://docs.ray.io/en/master/_static/js/top-navigation.js"></script>
    <script src="https://docs.ray.io/en/master/_static/js/tags.js"></script>
    <script src="https://docs.ray.io/en/master/_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="https://docs.ray.io/en/master/_static/design-tabs.js"></script>
    <script async="async" src="https://docs.ray.io/_/static/javascript/readthedocs-doc-embed.js"></script>
    <link rel="canonical" href="https://docs.ray.io/en/latest/train/distributed-pytorch/converting-existing-training-loop.html" />
    <link rel="shortcut icon" href="https://docs.ray.io/en/master/_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Data Loading and Preprocessing" href="data-loading-preprocessing.html" />
    <link rel="prev" title="Distributed PyTorch" href="../distributed-pytorch.html" />

<!-- Fathom - beautiful, simple website analytics -->
<script src="https://deer.ray.io/script.js" data-site="WYYANYOS" defer></script>
<!-- / Fathom -->

<script async src="https://www.googletagmanager.com/gtag/js?id=UA-110413294-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-110413294-1');
</script>

<script
  src="https://widget.kapa.ai/kapa-widget.bundle.js"
  data-website-id="18a8c339-4ec5-43c8-8182-db3f2bc8c6b6"
  data-project-name="Ray"
  data-project-color="#2C2C2C"
  data-project-logo="https://global.discourse-cdn.com/business7/uploads/ray/original/1X/8f4dcb72f7cd34e2a332d548bd65860994bc8ff1.png"
></script>

<script>
(function(apiKey){
    (function(p,e,n,d,o){var v,w,x,y,z;o=p[d]=p[d]||{};o._q=o._q||[];
    v=['initialize','identify','updateOptions','pageLoad','track'];for(w=0,x=v.length;w<x;++w)(function(m){
        o[m]=o[m]||function(){o._q[m===v[0]?'unshift':'push']([m].concat([].slice.call(arguments,0)));};})(v[w]);
        y=e.createElement(n);y.async=!0;y.src='https://cdn.pendo.io/agent/static/'+apiKey+'/pendo.js';
        z=e.getElementsByTagName(n)[0];z.parentNode.insertBefore(y,z);})(window,document,'script','pendo');

        pendo.initialize({
            visitor: {
                id: 'VISITOR-UNIQUE-ID'
            },
            account: {
                id: 'ACCOUNT-UNIQUE-ID'
            }
        });
})('f89fa48a-6dd7-4d7c-67cf-a8051ed891f2');
</script>



  
<!-- RTD Extra Head -->

<link rel="stylesheet" href="https://docs.ray.io/_/static/css/readthedocs-doc-embed.css" type="text/css" />

<script type="application/json" id="READTHEDOCS_DATA">{"ad_free": false, "api_host": "https://readthedocs.com", "builder": "sphinx", "canonical_url": null, "docroot": "/doc/source/", "features": {"docsearch_disabled": false}, "global_analytics_code": "UA-17997319-2", "language": "en", "page": "train/distributed-pytorch/converting-existing-training-loop", "programming_language": "py", "project": "anyscale-ray", "proxied_api_host": "/_", "source_suffix": ".rst", "subprojects": {}, "theme": "sphinx_book_theme", "user_analytics_code": "", "version": "master"}</script>

<!--
Using this variable directly instead of using `JSON.parse` is deprecated.
The READTHEDOCS_DATA global variable will be removed in the future.
-->
<script type="text/javascript">
READTHEDOCS_DATA = JSON.parse(document.getElementById('READTHEDOCS_DATA').innerHTML);
</script>

<script type="text/javascript" src="https://docs.ray.io/_/static/javascript/readthedocs-analytics.js" async="async"></script>

<!-- end RTD <extrahead> -->
</head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"><div class='topnav'></div></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Ray 3.0.0.dev0</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main Navigation">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../index.html">
                    Welcome to Ray!
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Ray
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../ray-overview/index.html">
   Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ray-overview/getting-started.html">
   Getting Started
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ray-more-libs/installation.html">
   Installation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ray-overview/use-cases.html">
   Use Cases
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ray-overview/examples.html">
   Example Gallery
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ray-overview/ray-libraries.html">
   Ecosystem
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ray-core/walkthrough.html">
   Ray Core
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../data/data.html">
   Ray Data
  </a>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../train.html">
   Ray Train
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="../key-concepts.html">
     Key Concepts
    </a>
   </li>
   <li class="toctree-l2 current active has-children">
    <a class="reference internal" href="../distributed-pytorch.html">
     Distributed PyTorch
    </a>
    <input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
    <label for="toctree-checkbox-2">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul class="current">
     <li class="toctree-l3 current active">
      <a class="current reference internal" href="converting-existing-training-loop.html#">
       Converting an Existing Training Loop
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="data-loading-preprocessing.html">
       Data Loading and Preprocessing
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="using-gpus.html">
       Configuring Scale and GPUs
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="persistent-storage.html">
       Configuring Persistent Storage
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="monitoring-logging.html">
       Monitoring and Logging
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="checkpoints.html">
       Saving and Loading Checkpoints
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="experiment-tracking.html">
       Experiment Tracking
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="fault-tolerance.html">
       Handling Failures and Node Preemption
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="advanced.html">
       Advanced Topics
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../more-frameworks.html">
     More Frameworks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../internals/index.html">
     Ray Train Internals
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../examples.html">
     Examples
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../faq.html">
     Ray Train FAQ
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../api/api.html">
     Ray Train API
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../tune.html">
   Ray Tune
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../serve/index.html">
   Ray Serve
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../rllib/index.html">
   Ray RLlib
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ray-more-libs/index.html">
   More Libraries
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ray-core/cluster/index.html">
   Ray Clusters
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ray-observability/index.html">
   Monitoring and Debugging
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ray-references/api.html">
   References
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ray-contribute/stability.html">
   Developer Guides
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/ray-project/ray"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ray-project/ray/issues/new?title=Issue%20on%20page%20%2Ftrain/distributed-pytorch/converting-existing-training-loop.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ray-project/ray/edit/master/doc/source/train/distributed-pytorch/converting-existing-training-loop.rst"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Edit this page"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="headerbtn__text-container">suggest edit</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://docs.ray.io/en/master/_sources/train/distributed-pytorch/converting-existing-training-loop.rst.txt"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.rst</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="converting-existing-training-loop.html#updating-your-training-function">
   Updating your training function
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="converting-existing-training-loop.html#creating-a-torchtrainer">
   Creating a
   <code class="xref py py-class docutils literal notranslate">
    <span class="pre">
     TorchTrainer
    </span>
   </code>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="converting-existing-training-loop.html#running-your-training-function">
   Running your training function
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="converting-existing-training-loop.html#configuring-training">
   Configuring Training
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="converting-existing-training-loop.html#accessing-training-results">
   Accessing Training Results
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="converting-existing-training-loop.html#hugging-face">
   Hugging Face
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="converting-existing-training-loop.html#transformerstrainer">
     TransformersTrainer
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="converting-existing-training-loop.html#acceleratetrainer">
     AccelerateTrainer
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Converting an Existing Training Loop</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="converting-existing-training-loop.html#updating-your-training-function">
   Updating your training function
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="converting-existing-training-loop.html#creating-a-torchtrainer">
   Creating a
   <code class="xref py py-class docutils literal notranslate">
    <span class="pre">
     TorchTrainer
    </span>
   </code>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="converting-existing-training-loop.html#running-your-training-function">
   Running your training function
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="converting-existing-training-loop.html#configuring-training">
   Configuring Training
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="converting-existing-training-loop.html#accessing-training-results">
   Accessing Training Results
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="converting-existing-training-loop.html#hugging-face">
   Hugging Face
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="converting-existing-training-loop.html#transformerstrainer">
     TransformersTrainer
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="converting-existing-training-loop.html#acceleratetrainer">
     AccelerateTrainer
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section id="converting-an-existing-training-loop">
<span id="train-porting-code"></span><h1>Converting an Existing Training Loop<a class="headerlink" href="converting-existing-training-loop.html#converting-an-existing-training-loop" title="Permalink to this headline">#</a></h1>
<p>The following instructions assume you have a training function
that can already be run on a single worker.</p>
<section id="updating-your-training-function">
<h2>Updating your training function<a class="headerlink" href="converting-existing-training-loop.html#updating-your-training-function" title="Permalink to this headline">#</a></h2>
<p>First, you’ll want to update your training function to support distributed
training.</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-0" name="sd-tab-set-0" type="radio">
</input><label class="sd-tab-label" for="sd-tab-item-0">
PyTorch</label><div class="sd-tab-content docutils">
<p>Ray Train will set up your distributed process group for you and also provides utility methods
to automatically prepare your model and data for distributed training.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Ray Train will still work even if you don’t use the <a class="reference internal" href="../api/doc/ray.train.torch.prepare_model.html#ray.train.torch.prepare_model" title="ray.train.torch.prepare_model"><code class="xref py py-func docutils literal notranslate"><span class="pre">ray.train.torch.prepare_model()</span></code></a>
and <a class="reference internal" href="../api/doc/ray.train.torch.prepare_data_loader.html#ray.train.torch.prepare_data_loader" title="ray.train.torch.prepare_data_loader"><code class="xref py py-func docutils literal notranslate"><span class="pre">ray.train.torch.prepare_data_loader()</span></code></a> utilities below,
and instead handle the logic directly inside your training function.</p>
</div>
<p>First, use the <a class="reference internal" href="../api/doc/ray.train.torch.prepare_model.html#ray.train.torch.prepare_model" title="ray.train.torch.prepare_model"><code class="xref py py-func docutils literal notranslate"><span class="pre">prepare_model()</span></code></a> function to automatically move your model to the right device and wrap it in
<code class="docutils literal notranslate"><span class="pre">DistributedDataParallel</span></code>:</p>
<div class="highlight-diff notranslate"><div class="highlight"><pre><span></span><span class="w"> </span>import torch<span class="w"></span>
<span class="w"> </span>from torch.nn.parallel import DistributedDataParallel<span class="w"></span>
<span class="gi">+from ray.air import session</span><span class="w"></span>
<span class="gi">+from ray import train</span><span class="w"></span>
<span class="gi">+import ray.train.torch</span><span class="w"></span>


<span class="w"> </span>def train_func():<span class="w"></span>
<span class="gd">-    device = torch.device(f&quot;cuda:{train.get_context().get_local_rank()}&quot; if</span><span class="w"></span>
<span class="gd">-        torch.cuda.is_available() else &quot;cpu&quot;)</span><span class="w"></span>
<span class="gd">-    torch.cuda.set_device(device)</span><span class="w"></span>

<span class="w"> </span>    # Create model.<span class="w"></span>
<span class="w"> </span>    model = NeuralNetwork()<span class="w"></span>

<span class="gd">-    model = model.to(device)</span><span class="w"></span>
<span class="gd">-    model = DistributedDataParallel(model,</span><span class="w"></span>
<span class="gd">-        device_ids=[train.get_context().get_local_rank()] if torch.cuda.is_available() else None)</span><span class="w"></span>

<span class="gi">+    model = train.torch.prepare_model(model)</span><span class="w"></span>

<span class="w"> </span>    ...<span class="w"></span>
</pre></div>
</div>
<p>Then, use the <code class="docutils literal notranslate"><span class="pre">prepare_data_loader</span></code> function to automatically add a <code class="docutils literal notranslate"><span class="pre">DistributedSampler</span></code> to your <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code>
and move the batches to the right device. This step is not necessary if you are passing in Ray Data to your Trainer
(see <a class="reference internal" href="data-loading-preprocessing.html#data-ingest-torch"><span class="std std-ref">Data Loading and Preprocessing</span></a>):</p>
<div class="highlight-diff notranslate"><div class="highlight"><pre><span></span><span class="w"> </span>import torch<span class="w"></span>
<span class="w"> </span>from torch.utils.data import DataLoader, DistributedSampler<span class="w"></span>
<span class="gi">+from ray import train</span><span class="w"></span>
<span class="gi">+import ray.train.torch</span><span class="w"></span>


<span class="w"> </span>def train_func():<span class="w"></span>
<span class="gd">-    device = torch.device(f&quot;cuda:{train.get_context().get_local_rank()}&quot; if</span><span class="w"></span>
<span class="gd">-        torch.cuda.is_available() else &quot;cpu&quot;)</span><span class="w"></span>
<span class="gd">-    torch.cuda.set_device(device)</span><span class="w"></span>

<span class="w"> </span>    ...<span class="w"></span>

<span class="gd">-    data_loader = DataLoader(my_dataset, batch_size=worker_batch_size, sampler=DistributedSampler(dataset))</span><span class="w"></span>

<span class="gi">+    data_loader = DataLoader(my_dataset, batch_size=worker_batch_size)</span><span class="w"></span>
<span class="gi">+    data_loader = train.torch.prepare_data_loader(data_loader)</span><span class="w"></span>

<span class="w"> </span>    for X, y in data_loader:<span class="w"></span>
<span class="gd">-        X = X.to_device(device)</span><span class="w"></span>
<span class="gd">-        y = y.to_device(device)</span><span class="w"></span>
</pre></div>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Keep in mind that <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code> takes in a <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> which is the batch size for each worker.
The global batch size can be calculated from the worker batch size (and vice-versa) with the following equation:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">global_batch_size</span> <span class="o">=</span> <span class="n">worker_batch_size</span> <span class="o">*</span> <span class="n">train</span><span class="o">.</span><span class="n">get_context</span><span class="p">()</span><span class="o">.</span><span class="n">get_world_size</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
</section>
<section id="creating-a-torchtrainer">
<h2>Creating a <a class="reference internal" href="../api/doc/ray.train.torch.TorchTrainer.html#ray.train.torch.TorchTrainer" title="ray.train.torch.TorchTrainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">TorchTrainer</span></code></a><a class="headerlink" href="converting-existing-training-loop.html#creating-a-torchtrainer" title="Permalink to this headline">#</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">Trainer</span></code>s are the primary Ray Train classes that are used to manage state and
execute training. For distributed PyTorch, we use a <a class="reference internal" href="../api/doc/ray.train.torch.TorchTrainer.html#ray.train.torch.TorchTrainer" title="ray.train.torch.TorchTrainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">TorchTrainer</span></code></a>
that you can setup like this:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ray.air</span> <span class="kn">import</span> <span class="n">ScalingConfig</span>
<span class="kn">from</span> <span class="nn">ray.train.torch</span> <span class="kn">import</span> <span class="n">TorchTrainer</span>
<span class="c1"># For GPU Training, set `use_gpu` to True.</span>
<span class="n">use_gpu</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">TorchTrainer</span><span class="p">(</span>
    <span class="n">train_func</span><span class="p">,</span>
    <span class="n">scaling_config</span><span class="o">=</span><span class="n">ScalingConfig</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="n">use_gpu</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
<p>To customize the backend setup, you can pass a
<a class="reference internal" href="../api/doc/ray.train.torch.TorchConfig.html#ray.train.torch.TorchConfig" title="ray.train.torch.TorchConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">TorchConfig</span></code></a>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ray.air</span> <span class="kn">import</span> <span class="n">ScalingConfig</span>
<span class="kn">from</span> <span class="nn">ray.train.torch</span> <span class="kn">import</span> <span class="n">TorchTrainer</span><span class="p">,</span> <span class="n">TorchConfig</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">TorchTrainer</span><span class="p">(</span>
    <span class="n">train_func</span><span class="p">,</span>
    <span class="n">torch_backend</span><span class="o">=</span><span class="n">TorchConfig</span><span class="p">(</span><span class="o">...</span><span class="p">),</span>
    <span class="n">scaling_config</span><span class="o">=</span><span class="n">ScalingConfig</span><span class="p">(</span><span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
<p>For more configurability, please reference the <a class="reference internal" href="../api/doc/ray.train.data_parallel_trainer.DataParallelTrainer.html#ray.train.data_parallel_trainer.DataParallelTrainer" title="ray.train.data_parallel_trainer.DataParallelTrainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">DataParallelTrainer</span></code></a> API.</p>
</section>
<section id="running-your-training-function">
<h2>Running your training function<a class="headerlink" href="converting-existing-training-loop.html#running-your-training-function" title="Permalink to this headline">#</a></h2>
<p>With a distributed training function and a Ray Train <code class="docutils literal notranslate"><span class="pre">Trainer</span></code>, you are now
ready to start training!</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="configuring-training">
<h2>Configuring Training<a class="headerlink" href="converting-existing-training-loop.html#configuring-training" title="Permalink to this headline">#</a></h2>
<p>With Ray Train, you can execute a training function (<code class="docutils literal notranslate"><span class="pre">train_func</span></code>) in a
distributed manner by calling <code class="docutils literal notranslate"><span class="pre">Trainer.fit</span></code>. To pass arguments
into the training function, you can expose a single <code class="docutils literal notranslate"><span class="pre">config</span></code> dictionary parameter:</p>
<div class="highlight-diff notranslate"><div class="highlight"><pre><span></span><span class="gd">-def train_func():</span><span class="w"></span>
<span class="gi">+def train_func(config):</span><span class="w"></span>
</pre></div>
</div>
<p>Then, you can pass in the config dictionary as an argument to <code class="docutils literal notranslate"><span class="pre">Trainer</span></code>:</p>
<div class="highlight-diff notranslate"><div class="highlight"><pre><span></span><span class="gi">+config = {} # This should be populated.</span><span class="w"></span>
<span class="w"> </span>trainer = TorchTrainer(<span class="w"></span>
<span class="w"> </span>    train_func,<span class="w"></span>
<span class="gi">+    train_loop_config=config,</span><span class="w"></span>
<span class="w"> </span>    scaling_config=ScalingConfig(num_workers=2)<span class="w"></span>
<span class="w"> </span>)<span class="w"></span>
</pre></div>
</div>
<p>Putting this all together, you can run your training function with different
configurations. As an example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ray</span> <span class="kn">import</span> <span class="n">train</span>
<span class="kn">from</span> <span class="nn">ray.air</span> <span class="kn">import</span> <span class="n">ScalingConfig</span>
<span class="kn">from</span> <span class="nn">ray.train.torch</span> <span class="kn">import</span> <span class="n">TorchTrainer</span>

<span class="k">def</span> <span class="nf">train_func</span><span class="p">(</span><span class="n">config</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;num_epochs&quot;</span><span class="p">]):</span>
        <span class="n">train</span><span class="o">.</span><span class="n">report</span><span class="p">({</span><span class="s2">&quot;epoch&quot;</span><span class="p">:</span> <span class="n">i</span><span class="p">})</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">TorchTrainer</span><span class="p">(</span>
    <span class="n">train_func</span><span class="p">,</span>
    <span class="n">train_loop_config</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;num_epochs&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">},</span>
    <span class="n">scaling_config</span><span class="o">=</span><span class="n">ScalingConfig</span><span class="p">(</span><span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">metrics</span><span class="p">[</span><span class="s2">&quot;num_epochs&quot;</span><span class="p">])</span>
<span class="c1"># 1</span>
</pre></div>
</div>
<p>A primary use-case for <code class="docutils literal notranslate"><span class="pre">config</span></code> is to try different hyperparameters. To
perform hyperparameter tuning with Ray Train, please refer to the
<a class="reference internal" href="hyperparameter-optimization.html#train-tune"><span class="std std-ref">Ray Tune integration</span></a>.</p>
</section>
<section id="accessing-training-results">
<span id="train-result-object"></span><h2>Accessing Training Results<a class="headerlink" href="converting-existing-training-loop.html#accessing-training-results" title="Permalink to this headline">#</a></h2>
<p>The return of a <code class="docutils literal notranslate"><span class="pre">Trainer.fit</span></code> is a <a class="reference internal" href="../../tune/api/doc/ray.air.Result.html#ray.air.Result" title="ray.air.result.Result"><code class="xref py py-class docutils literal notranslate"><span class="pre">Result</span></code></a> object, containing
information about the training run. You can access it to obtain saved checkpoints,
metrics and other relevant data.</p>
<p>For example, you can:</p>
<ul class="simple">
<li><p>Print the metrics for the last training iteration:</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pprint</span> <span class="kn">import</span> <span class="n">pprint</span>

<span class="n">pprint</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">metrics</span><span class="p">)</span>
<span class="c1"># {&#39;_time_this_iter_s&#39;: 0.001016855239868164,</span>
<span class="c1">#  &#39;_timestamp&#39;: 1657829125,</span>
<span class="c1">#  &#39;_training_iteration&#39;: 2,</span>
<span class="c1">#  &#39;config&#39;: {},</span>
<span class="c1">#  &#39;date&#39;: &#39;2022-07-14_20-05-25&#39;,</span>
<span class="c1">#  &#39;done&#39;: True,</span>
<span class="c1">#  &#39;episodes_total&#39;: None,</span>
<span class="c1">#  &#39;epoch&#39;: 1,</span>
<span class="c1">#  &#39;experiment_id&#39;: &#39;5a3f8b9bf875437881a8ddc7e4dd3340&#39;,</span>
<span class="c1">#  &#39;experiment_tag&#39;: &#39;0&#39;,</span>
<span class="c1">#  &#39;hostname&#39;: &#39;ip-172-31-43-110&#39;,</span>
<span class="c1">#  &#39;iterations_since_restore&#39;: 2,</span>
<span class="c1">#  &#39;node_ip&#39;: &#39;172.31.43.110&#39;,</span>
<span class="c1">#  &#39;pid&#39;: 654068,</span>
<span class="c1">#  &#39;time_since_restore&#39;: 3.4353830814361572,</span>
<span class="c1">#  &#39;time_this_iter_s&#39;: 0.00809168815612793,</span>
<span class="c1">#  &#39;time_total_s&#39;: 3.4353830814361572,</span>
<span class="c1">#  &#39;timestamp&#39;: 1657829125,</span>
<span class="c1">#  &#39;timesteps_since_restore&#39;: 0,</span>
<span class="c1">#  &#39;timesteps_total&#39;: None,</span>
<span class="c1">#  &#39;training_iteration&#39;: 2,</span>
<span class="c1">#  &#39;trial_id&#39;: &#39;4913f_00000&#39;,</span>
<span class="c1">#  &#39;warmup_time&#39;: 0.003167867660522461}</span>
</pre></div>
</div>
<ul class="simple">
<li><p>View the dataframe containing the metrics from all iterations:</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">metrics_dataframe</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Obtain the <a class="reference internal" href="../../ray-air/api/doc/ray.air.checkpoint.Checkpoint.html#ray.air.checkpoint.Checkpoint" title="ray.air.checkpoint.Checkpoint"><code class="xref py py-class docutils literal notranslate"><span class="pre">Checkpoint</span></code></a>, used for resuming training, prediction and serving.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">result</span><span class="o">.</span><span class="n">checkpoint</span>  <span class="c1"># last saved checkpoint</span>
<span class="n">result</span><span class="o">.</span><span class="n">best_checkpoints</span>  <span class="c1"># N best saved checkpoints, as configured in run_config</span>
<span class="n">result</span><span class="o">.</span><span class="n">error</span>  <span class="c1"># returns the Exception if training failed.</span>
</pre></div>
</div>
<p>See <a class="reference internal" href="../../tune/api/doc/ray.air.Result.html#ray.air.Result" title="ray.air.result.Result"><code class="xref py py-class docutils literal notranslate"><span class="pre">the</span> <span class="pre">Result</span> <span class="pre">docstring</span></code></a> for more details.</p>
</section>
<section id="hugging-face">
<span id="train-huggingface"></span><h2>Hugging Face<a class="headerlink" href="converting-existing-training-loop.html#hugging-face" title="Permalink to this headline">#</a></h2>
<section id="transformerstrainer">
<h3>TransformersTrainer<a class="headerlink" href="converting-existing-training-loop.html#transformerstrainer" title="Permalink to this headline">#</a></h3>
<p><a class="reference internal" href="../api/doc/ray.train.huggingface.TransformersTrainer.html#ray.train.huggingface.TransformersTrainer" title="ray.train.huggingface.TransformersTrainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">TransformersTrainer</span></code></a> further extends <a class="reference internal" href="../api/doc/ray.train.torch.TorchTrainer.html#ray.train.torch.TorchTrainer" title="ray.train.torch.TorchTrainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">TorchTrainer</span></code></a>, built
for interoperability with the HuggingFace Transformers library.</p>
<p>Users are required to provide a <code class="docutils literal notranslate"><span class="pre">trainer_init_per_worker</span></code> function which returns a
<code class="docutils literal notranslate"><span class="pre">transformers.Trainer</span></code> object. The <code class="docutils literal notranslate"><span class="pre">trainer_init_per_worker</span></code> function
will have access to preprocessed train and evaluation datasets.</p>
<p>Upon calling <code class="xref py py-obj docutils literal notranslate"><span class="pre">TransformersTrainer.fit()</span></code>, multiple workers (ray actors) will be spawned,
and each worker will create its own copy of a <code class="docutils literal notranslate"><span class="pre">transformers.Trainer</span></code>.</p>
<p>Each worker will then invoke <code class="docutils literal notranslate"><span class="pre">transformers.Trainer.train()</span></code>, which will perform distributed
training via Pytorch DDP.</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
Code example<div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="c1"># Based on</span>
<span class="c1"># huggingface/notebooks/examples/language_modeling_from_scratch.ipynb</span>

<span class="c1"># Hugging Face imports</span>
<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">import</span> <span class="nn">transformers</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoConfig</span><span class="p">,</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoTokenizer</span>

<span class="kn">import</span> <span class="nn">ray</span>
<span class="kn">from</span> <span class="nn">ray.train.huggingface</span> <span class="kn">import</span> <span class="n">TransformersTrainer</span>
<span class="kn">from</span> <span class="nn">ray.train</span> <span class="kn">import</span> <span class="n">ScalingConfig</span>


<span class="c1"># If using GPUs, set this to True.</span>
<span class="n">use_gpu</span> <span class="o">=</span> <span class="kc">False</span>

<span class="n">model_checkpoint</span> <span class="o">=</span> <span class="s2">&quot;gpt2&quot;</span>
<span class="n">tokenizer_checkpoint</span> <span class="o">=</span> <span class="s2">&quot;sgugger/gpt2-like-tokenizer&quot;</span>
<span class="n">block_size</span> <span class="o">=</span> <span class="mi">128</span>

<span class="n">datasets</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;wikitext&quot;</span><span class="p">,</span> <span class="s2">&quot;wikitext-2-raw-v1&quot;</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">tokenizer_checkpoint</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">])</span>


<span class="n">tokenized_datasets</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
    <span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_proc</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span>
<span class="p">)</span>


<span class="k">def</span> <span class="nf">group_texts</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>
    <span class="c1"># Concatenate all texts.</span>
    <span class="n">concatenated_examples</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="nb">sum</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="p">[])</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">examples</span><span class="o">.</span><span class="n">keys</span><span class="p">()}</span>
    <span class="n">total_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">concatenated_examples</span><span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="n">examples</span><span class="o">.</span><span class="n">keys</span><span class="p">())[</span><span class="mi">0</span><span class="p">]])</span>
    <span class="c1"># We drop the small remainder, we could add padding if the model</span>
    <span class="c1"># supported it.</span>
    <span class="c1"># instead of this drop, you can customize this part to your needs.</span>
    <span class="n">total_length</span> <span class="o">=</span> <span class="p">(</span><span class="n">total_length</span> <span class="o">//</span> <span class="n">block_size</span><span class="p">)</span> <span class="o">*</span> <span class="n">block_size</span>
    <span class="c1"># Split by chunks of max_len.</span>
    <span class="n">result</span> <span class="o">=</span> <span class="p">{</span>
        <span class="n">k</span><span class="p">:</span> <span class="p">[</span><span class="n">t</span><span class="p">[</span><span class="n">i</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">block_size</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">total_length</span><span class="p">,</span> <span class="n">block_size</span><span class="p">)]</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">concatenated_examples</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
    <span class="p">}</span>
    <span class="n">result</span><span class="p">[</span><span class="s2">&quot;labels&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">result</span>


<span class="n">lm_datasets</span> <span class="o">=</span> <span class="n">tokenized_datasets</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
    <span class="n">group_texts</span><span class="p">,</span>
    <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
    <span class="n">num_proc</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">ray_train_ds</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">from_huggingface</span><span class="p">(</span><span class="n">lm_datasets</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">])</span>
<span class="n">ray_evaluation_ds</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">from_huggingface</span><span class="p">(</span><span class="n">lm_datasets</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">])</span>


<span class="k">def</span> <span class="nf">trainer_init_per_worker</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">eval_dataset</span><span class="p">,</span> <span class="o">**</span><span class="n">config</span><span class="p">):</span>
    <span class="n">model_config</span> <span class="o">=</span> <span class="n">AutoConfig</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_checkpoint</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span><span class="n">model_config</span><span class="p">)</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">transformers</span><span class="o">.</span><span class="n">TrainingArguments</span><span class="p">(</span>
        <span class="n">output_dir</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_checkpoint</span><span class="si">}</span><span class="s2">-wikitext2&quot;</span><span class="p">,</span>
        <span class="n">evaluation_strategy</span><span class="o">=</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span>
        <span class="n">save_strategy</span><span class="o">=</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span>
        <span class="n">logging_strategy</span><span class="o">=</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span>
        <span class="n">learning_rate</span><span class="o">=</span><span class="mf">2e-5</span><span class="p">,</span>
        <span class="n">weight_decay</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
        <span class="n">no_cuda</span><span class="o">=</span><span class="p">(</span><span class="ow">not</span> <span class="n">use_gpu</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">transformers</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="n">args</span><span class="o">=</span><span class="n">args</span><span class="p">,</span>
        <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span>
        <span class="n">eval_dataset</span><span class="o">=</span><span class="n">eval_dataset</span><span class="p">,</span>
    <span class="p">)</span>


<span class="n">scaling_config</span> <span class="o">=</span> <span class="n">ScalingConfig</span><span class="p">(</span><span class="n">num_workers</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">use_gpu</span><span class="o">=</span><span class="n">use_gpu</span><span class="p">)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">TransformersTrainer</span><span class="p">(</span>
    <span class="n">trainer_init_per_worker</span><span class="o">=</span><span class="n">trainer_init_per_worker</span><span class="p">,</span>
    <span class="n">scaling_config</span><span class="o">=</span><span class="n">scaling_config</span><span class="p">,</span>
    <span class="n">datasets</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">ray_train_ds</span><span class="p">,</span> <span class="s2">&quot;evaluation&quot;</span><span class="p">:</span> <span class="n">ray_evaluation_ds</span><span class="p">},</span>
<span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

</pre></div>
</div>
</div>
</details></section>
<section id="acceleratetrainer">
<h3>AccelerateTrainer<a class="headerlink" href="converting-existing-training-loop.html#acceleratetrainer" title="Permalink to this headline">#</a></h3>
<p>If you prefer a more fine-grained Hugging Face API than what Transformers provides, you can use <a class="reference internal" href="../api/doc/ray.train.huggingface.AccelerateTrainer.html#ray.train.huggingface.AccelerateTrainer" title="ray.train.huggingface.AccelerateTrainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">AccelerateTrainer</span></code></a>
to run training functions making use of Hugging Face Accelerate. Similarly to <a class="reference internal" href="../api/doc/ray.train.huggingface.TransformersTrainer.html#ray.train.huggingface.TransformersTrainer" title="ray.train.huggingface.TransformersTrainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">TransformersTrainer</span></code></a>, <a class="reference internal" href="../api/doc/ray.train.huggingface.AccelerateTrainer.html#ray.train.huggingface.AccelerateTrainer" title="ray.train.huggingface.AccelerateTrainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">AccelerateTrainer</span></code></a>
is also an extension of <a class="reference internal" href="../api/doc/ray.train.torch.TorchTrainer.html#ray.train.torch.TorchTrainer" title="ray.train.torch.TorchTrainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">TorchTrainer</span></code></a>.</p>
<p><a class="reference internal" href="../api/doc/ray.train.huggingface.AccelerateTrainer.html#ray.train.huggingface.AccelerateTrainer" title="ray.train.huggingface.AccelerateTrainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">AccelerateTrainer</span></code></a> allows you to pass an Accelerate configuration file generated with <code class="docutils literal notranslate"><span class="pre">accelerate</span> <span class="pre">config</span></code> to be applied on all training workers.
This ensures that the worker environments are set up correctly for Accelerate, allowing you to take advantage of Accelerate APIs and integrations such as DeepSpeed and FSDP
just as you would if you were running Accelerate without Ray.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">AccelerateTrainer</span></code> will override some settings set with <code class="docutils literal notranslate"><span class="pre">accelerate</span> <span class="pre">config</span></code>, mainly related to
the topology and networking. See the <a class="reference internal" href="../api/doc/ray.train.huggingface.AccelerateTrainer.html#ray.train.huggingface.AccelerateTrainer" title="ray.train.huggingface.AccelerateTrainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">AccelerateTrainer</span></code></a>
API reference for more details.</p>
</div>
<p>Aside from Accelerate support, the usage is identical to <a class="reference internal" href="../api/doc/ray.train.torch.TorchTrainer.html#ray.train.torch.TorchTrainer" title="ray.train.torch.TorchTrainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">TorchTrainer</span></code></a>, meaning you define your own training function
and use the <a class="reference internal" href="../api/doc/ray.train.report.html#ray.train.report" title="ray.train.report"><code class="xref py py-func docutils literal notranslate"><span class="pre">report()</span></code></a> API to report metrics, save checkpoints etc.</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
Code example<div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>

<span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>

<span class="kn">import</span> <span class="nn">ray</span>
<span class="kn">from</span> <span class="nn">ray</span> <span class="kn">import</span> <span class="n">train</span>
<span class="kn">from</span> <span class="nn">ray.train</span> <span class="kn">import</span> <span class="n">Checkpoint</span><span class="p">,</span> <span class="n">ScalingConfig</span>
<span class="kn">from</span> <span class="nn">ray.train.huggingface</span> <span class="kn">import</span> <span class="n">AccelerateTrainer</span>


<span class="c1"># If using GPUs, set this to True.</span>
<span class="n">use_gpu</span> <span class="o">=</span> <span class="kc">False</span>


<span class="n">input_size</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">layer_size</span> <span class="o">=</span> <span class="mi">15</span>
<span class="n">output_size</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">3</span>


<span class="k">class</span> <span class="nc">NeuralNetwork</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">NeuralNetwork</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">layer_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">layer_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layer1</span><span class="p">(</span><span class="nb">input</span><span class="p">)))</span>


<span class="k">def</span> <span class="nf">train_loop_per_worker</span><span class="p">():</span>
    <span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>
    <span class="n">dataset_shard</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">get_dataset_shard</span><span class="p">(</span><span class="s2">&quot;train&quot;</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">NeuralNetwork</span><span class="p">()</span>
    <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

    <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">batches</span> <span class="ow">in</span> <span class="n">dataset_shard</span><span class="o">.</span><span class="n">iter_torch_batches</span><span class="p">(</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">dtypes</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span>
        <span class="p">):</span>
            <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">batches</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">],</span> <span class="mi">1</span><span class="p">),</span> <span class="n">batches</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">]</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;epoch: </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">, loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">train</span><span class="o">.</span><span class="n">report</span><span class="p">(</span>
            <span class="p">{},</span>
            <span class="n">checkpoint</span><span class="o">=</span><span class="n">Checkpoint</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span>
                <span class="nb">dict</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">accelerator</span><span class="o">.</span><span class="n">unwrap_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
            <span class="p">),</span>
        <span class="p">)</span>


<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">from_items</span><span class="p">([{</span><span class="s2">&quot;x&quot;</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">:</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="mi">1</span><span class="p">}</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">200</span><span class="p">)])</span>
<span class="n">scaling_config</span> <span class="o">=</span> <span class="n">ScalingConfig</span><span class="p">(</span><span class="n">num_workers</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">use_gpu</span><span class="o">=</span><span class="n">use_gpu</span><span class="p">)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">AccelerateTrainer</span><span class="p">(</span>
    <span class="n">train_loop_per_worker</span><span class="o">=</span><span class="n">train_loop_per_worker</span><span class="p">,</span>
    <span class="c1"># Instead of using a dict, you can run ``accelerate config``.</span>
    <span class="c1"># The default value of None will then load that configuration</span>
    <span class="c1"># file.</span>
    <span class="n">accelerate_config</span><span class="o">=</span><span class="p">{},</span>
    <span class="n">scaling_config</span><span class="o">=</span><span class="n">scaling_config</span><span class="p">,</span>
    <span class="n">datasets</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">train_dataset</span><span class="p">},</span>
<span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details></section>
</section>
</section>


              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="../distributed-pytorch.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Distributed PyTorch</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="data-loading-preprocessing.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Data Loading and Preprocessing</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><!-- Override the footer area for the sphinx-book-theme to include the CSAT widget -->
<div id="csat">
  <div id="csat-feedback-received" class="csat-hidden">
    <span>Thanks for the feedback!</span>
  </div>
  <div id="csat-inputs">
    <span>Was this helpful?</span>
    <div id="csat-yes" class="csat-button">
      <svg id="csat-yes-icon" class="csat-hidden csat-icon" width="18" height="13" viewBox="0 0 18 13" fill="none" xmlns="http://www.w3.org/2000/svg">
        <path d="M7.00023 10.172L16.1922 0.979004L17.6072 2.393L7.00023 13L0.63623 6.636L2.05023 5.222L7.00023 10.172Z" fill="black"/>
      </svg>
      <span>Yes<span>
    </div>
    <div id="csat-no" class="csat-button">
      <svg id="csat-no-icon" class="csat-hidden csat-icon" width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg">
        <path d="M7.00023 5.58599L11.9502 0.635986L13.3642 2.04999L8.41423 6.99999L13.3642 11.95L11.9502 13.364L7.00023 8.41399L2.05023 13.364L0.63623 11.95L5.58623 6.99999L0.63623 2.04999L2.05023 0.635986L7.00023 5.58599Z" fill="black"/>
      </svg>
      <span>No<span>
    </div>
  </div>
  <div id="csat-textarea-group" class="csat-hidden">
    <span id="csat-feedback-label">Feedback</span>
    <textarea id="csat-textarea"></textarea>
    <div id="csat-submit">Submit</div>
  </div>
</div><p>
  
    By The Ray Team<br/>
  
      &copy; Copyright 2023, The Ray Team.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="https://docs.ray.io/en/master/_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>