{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "import openai\n",
    "from llama_index import ServiceContext\n",
    "from llama_index.llms import OpenAI\n",
    "from llama_index.schema import MetadataMode\n",
    "\n",
    "nest_asyncio.apply()\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "llm = OpenAI(temperature=0.1, model=\"gpt-3.5-turbo\", max_tokens=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.node_parser import SimpleNodeParser\n",
    "from llama_index.node_parser.extractors import (\n",
    "    MetadataExtractor,\n",
    "    SummaryExtractor,\n",
    "    QuestionsAnsweredExtractor,\n",
    "    TitleExtractor,\n",
    "    KeywordExtractor,\n",
    "    EntityExtractor,\n",
    "    MetadataFeatureExtractor,\n",
    ")\n",
    "from llama_index.text_splitter import TokenTextSplitter\n",
    "\n",
    "text_splitter = TokenTextSplitter(separator=\" \", chunk_size=512, chunk_overlap=128)\n",
    "\n",
    "\n",
    "class CustomExtractor(MetadataFeatureExtractor):\n",
    "    def extract(self, nodes):\n",
    "        metadata_list = [\n",
    "            {\n",
    "                \"custom\": node.metadata[\"document_title\"]\n",
    "                + \"\\n\"\n",
    "                + node.metadata[\"excerpt_keywords\"]\n",
    "            }\n",
    "            for node in nodes\n",
    "        ]\n",
    "        return metadata_list\n",
    "\n",
    "\n",
    "metadata_extractor = MetadataExtractor(\n",
    "    extractors=[\n",
    "        TitleExtractor(nodes=5, llm=llm),\n",
    "        QuestionsAnsweredExtractor(questions=3, llm=llm),\n",
    "        # EntityExtractor(prediction_threshold=0.5),\n",
    "        SummaryExtractor(summaries=[\"prev\", \"self\"], llm=llm),\n",
    "        KeywordExtractor(keywords=10, llm=llm),\n",
    "        CustomExtractor()\n",
    "    ],\n",
    ")\n",
    "\n",
    "node_parser = SimpleNodeParser(\n",
    "    text_splitter=text_splitter,\n",
    "    metadata_extractor=metadata_extractor,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader\n",
    "# Note the uninformative document file name, which may be a common scenario in a production setting\n",
    "uber_docs = SimpleDirectoryReader(input_files=[\"../data/LuocsuNganhDaukhiPhan1.pdf\"]).load_data()\n",
    "uber_docs = uber_docs[0:3]\n",
    "uber_nodes = node_parser.get_nodes_from_documents(uber_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'page_label': '1',\n",
       " 'file_name': 'LuocsuNganhDaukhiPhan1.pdf',\n",
       " 'document_title': \"The Comprehensive History and Contributions of Vietnam's Oil and Gas Industry (1961-2020)\",\n",
       " 'questions_this_excerpt_can_answer': \"1. What were the major achievements and contributions of Vietnam's oil and gas industry from 1961 to 2020?\\n2. How did the oil and gas industry in Vietnam fulfill the aspirations of President Ho Chi Minh, the Party, the State, and the people?\\n3. What were the significant milestones, challenges, and efforts made by the oil and gas industry in Vietnam during the 1980s and the early decades of the 21st century?\",\n",
       " 'prev_section_summary': 'The section discusses the significant contributions of the oil and gas industry to the economic development of Vietnam over the past half-century. It highlights the special attention given by the Party and the State to the industry in terms of policies, strategies, and timely guidance in various activities such as personnel management, professional work, logistics services, and international trade issues. The section also mentions the successful realization of the aspirations of President Ho Chi Minh, the Party, the State, and the people of Vietnam. The section concludes by mentioning the year 2011 and the Oil and Gas Group.',\n",
       " 'section_summary': \"The section discusses the successful achievements of the oil and gas industry in Vietnam, fulfilling the aspirations of President Ho Chi Minh, the Party, the State, and the people. It mentions the launch of a comprehensive three-volume history of the industry from 1961 to 2010, consisting of 1,700 pages. The history book provides valuable insights into the industry's activities, efforts, and significant contributions to Vietnam's economic development from the 1980s to the early decades of the 21st century.\",\n",
       " 'excerpt_keywords': 'Dầu khí, thành công, mong ước, Chủ tịch Hồ Chí Minh, Đảng, Nhà nước, Nhân dân, Tập đoàn Dầu khí Việt Nam, Lịch sử, tư liệu, sự kiện, hồi ức, chặng đường hoạt động, cố gắng nỗ lực, đóng góp, phát triển, nền kinh tế, thập niên 80, thế kỷ XX.',\n",
       " 'custom': \"The Comprehensive History and Contributions of Vietnam's Oil and Gas Industry (1961-2020)\\nDầu khí, thành công, mong ước, Chủ tịch Hồ Chí Minh, Đảng, Nhà nước, Nhân dân, Tập đoàn Dầu khí Việt Nam, Lịch sử, tư liệu, sự kiện, hồi ức, chặng đường hoạt động, cố gắng nỗ lực, đóng góp, phát triển, nền kinh tế, thập niên 80, thế kỷ XX.\"}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uber_nodes[2].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Given a user question, and a list of tools, output a list of relevant sub-questions in json markdown that when composed can help answer the full user question:\\n\\n# Example 1\\n<Tools>\\n```json\\n{{\\n    \"uber_10k\": \"Provides information about Uber financials for year 2021\",\\n    \"lyft_10k\": \"Provides information about Lyft financials for year 2021\"\\n}}\\n```\\n\\n<User Question>\\nCompare and contrast the revenue growth and EBITDA of Uber and Lyft for year 2021\\n\\n\\n<Output>\\n```json\\n[\\n    {{\\n        \"sub_question\": \"What is the revenue growth of Uber\",\\n        \"tool_name\": \"uber_10k\"\\n    }},\\n    {{\\n        \"sub_question\": \"What is the EBITDA of Uber\",\\n        \"tool_name\": \"uber_10k\"\\n    }},\\n    {{\\n        \"sub_question\": \"What is the revenue growth of Lyft\",\\n        \"tool_name\": \"lyft_10k\"\\n    }},\\n    {{\\n        \"sub_question\": \"What is the EBITDA of Lyft\",\\n        \"tool_name\": \"lyft_10k\"\\n    }}\\n]\\n```\\n\\n# Example 2\\n<Tools>\\n```json\\n{tools_str}\\n```\\n\\n<User Question>\\n{query_str}\\n\\n<Output>\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.question_gen.llm_generators import LLMQuestionGenerator\n",
    "from llama_index.question_gen.prompts import DEFAULT_SUB_QUESTION_PROMPT_TMPL\n",
    "\n",
    "service_context = ServiceContext.from_defaults(llm=llm, node_parser=node_parser)\n",
    "question_gen = LLMQuestionGenerator.from_defaults(\n",
    "    service_context=service_context,\n",
    "    prompt_template_str=\"\"\"\n",
    "        Follow the example, but instead of giving a question, always prefix the question \n",
    "        with: 'By first identifying and quoting the most relevant sources, '. \n",
    "        \"\"\"\n",
    "    + DEFAULT_SUB_QUESTION_PROMPT_TMPL,\n",
    ")\n",
    "DEFAULT_SUB_QUESTION_PROMPT_TMPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a user question, and a list of tools, output a list of relevant sub-questions in json markdown that when composed can help answer the full user question:\n",
      "\n",
      "# Example 1\n",
      "<Tools>\n",
      "```json\n",
      "{{\n",
      "    \"uber_10k\": \"Provides information about Uber financials for year 2021\",\n",
      "    \"lyft_10k\": \"Provides information about Lyft financials for year 2021\"\n",
      "}}\n",
      "```\n",
      "\n",
      "<User Question>\n",
      "Compare and contrast the revenue growth and EBITDA of Uber and Lyft for year 2021\n",
      "\n",
      "\n",
      "<Output>\n",
      "```json\n",
      "[\n",
      "    {{\n",
      "        \"sub_question\": \"What is the revenue growth of Uber\",\n",
      "        \"tool_name\": \"uber_10k\"\n",
      "    }},\n",
      "    {{\n",
      "        \"sub_question\": \"What is the EBITDA of Uber\",\n",
      "        \"tool_name\": \"uber_10k\"\n",
      "    }},\n",
      "    {{\n",
      "        \"sub_question\": \"What is the revenue growth of Lyft\",\n",
      "        \"tool_name\": \"lyft_10k\"\n",
      "    }},\n",
      "    {{\n",
      "        \"sub_question\": \"What is the EBITDA of Lyft\",\n",
      "        \"tool_name\": \"lyft_10k\"\n",
      "    }}\n",
      "]\n",
      "```\n",
      "\n",
      "# Example 2\n",
      "<Tools>\n",
      "```json\n",
      "{tools_str}\n",
      "```\n",
      "\n",
      "<User Question>\n",
      "{query_str}\n",
      "\n",
      "<Output>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "from llama_index.question_gen.prompts import DEFAULT_SUB_QUESTION_PROMPT_TMPL\n",
    "print(textwrap.dedent(DEFAULT_SUB_QUESTION_PROMPT_TMPL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Querying an Index With No Extra Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "nodes_no_metadata = deepcopy(uber_nodes) + deepcopy(lyft_nodes)\n",
    "for node in nodes_no_metadata:\n",
    "    node.metadata = {\n",
    "        k: node.metadata[k] for k in node.metadata if k in [\"page_label\", \"file_name\"]\n",
    "    }\n",
    "print(\"LLM sees:\\n\", (nodes_no_metadata)[9].get_content(metadata_mode=MetadataMode.LLM))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex\n",
    "from llama_index.query_engine import SubQuestionQueryEngine\n",
    "from llama_index.tools import QueryEngineTool, ToolMetadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_no_metadata = VectorStoreIndex(\n",
    "    nodes=nodes_no_metadata,\n",
    "    service_context=ServiceContext.from_defaults(llm=OpenAI(model=\"gpt-4\")),\n",
    ")\n",
    "engine_no_metadata = index_no_metadata.as_query_engine(\n",
    "    similarity_top_k=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_engine_no_metadata = SubQuestionQueryEngine.from_defaults(\n",
    "    query_engine_tools=[\n",
    "        QueryEngineTool(\n",
    "            query_engine=engine_no_metadata,\n",
    "            metadata=ToolMetadata(\n",
    "                name=\"sec_filing_documents\",\n",
    "                description=\"financial information on companies\",\n",
    "            ),\n",
    "        )\n",
    "    ],\n",
    "    question_gen=question_gen,\n",
    "    use_async=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_no_metadata = final_engine_no_metadata.query(\n",
    "    \"\"\"\n",
    "    What was the cost due to research and development v.s. sales and marketing for uber and lyft in 2019 in millions of USD?\n",
    "    Give your answer as a JSON.\n",
    "    \"\"\"\n",
    ")\n",
    "print(response_no_metadata.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Querying an Index With Extracted Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"LLM sees:\\n\",\n",
    "    (uber_nodes + lyft_nodes)[9].get_content(metadata_mode=MetadataMode.LLM),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex(\n",
    "    nodes=uber_nodes + lyft_nodes,\n",
    "    service_context=ServiceContext.from_defaults(llm=OpenAI(model=\"gpt-4\")),\n",
    ")\n",
    "engine = index.as_query_engine(\n",
    "    similarity_top_k=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_engine = SubQuestionQueryEngine.from_defaults(\n",
    "    query_engine_tools=[\n",
    "        QueryEngineTool(\n",
    "            query_engine=engine,\n",
    "            metadata=ToolMetadata(\n",
    "                name=\"sec_filing_documents\",\n",
    "                description=\"financial information on companies.\",\n",
    "            ),\n",
    "        )\n",
    "    ],\n",
    "    question_gen=question_gen,\n",
    "    use_async=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = final_engine.query(\n",
    "    \"\"\"\n",
    "    What was the cost due to research and development v.s. sales and marketing for uber and lyft in 2019 in millions of USD?\n",
    "    Give your answer as a JSON.\n",
    "    \"\"\"\n",
    ")\n",
    "print(response.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenges Identified in the Problem Domain\n",
    "In this example, we observed that the search quality as provided by vector embeddings was __rather poor__. This was likely due to _highly dense financial documents_ that were likely not representative of the training set for the model.\n",
    "In order to improve the search quality, other methods of neural search that employ more _keyword-based_ approaches may help, such as `ColBERTv2/PLAID`. In particular, this would help in matching on particular keywords to identify high-relevance chunks.\n",
    "Other valid steps may include utilizing models that are fine-tuned on financial datasets such as Bloomberg GPT.\n",
    "Finally, we can help to further _enrich the metadata_ by providing more contextual information regarding the surrounding context that the chunk is located in.\n",
    "#### Improvements to this Example\n",
    "Generally, this example can be improved further with more rigorous evaluation of both the __metadata extraction accuracy__, and the accuracy and recall of the QnA pipeline. Further, __incorporating a larger set of documents__ as well as the full length documents, which may provide more confounding passages that are difficult to disambiguate, could further stresss test the system we have built and suggest further improvements."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "booksage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
