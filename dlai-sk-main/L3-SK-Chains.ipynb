{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52824b89-532a-4e54-87e9-1410813cd39e",
   "metadata": {},
   "source": [
    "# Chains in SK\n",
    "\n",
    "## Outline\n",
    "\n",
    "* Sequential Chains with kernel.run_async\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "541eb2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7ed03ed-1322-49e3-b2a2-33e94fb592ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b84e441b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "974acf8e-8f88-42de-88f8-40a82cb58e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7a09c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Queen Size Sheet Set</td>\n",
       "      <td>I ordered a king size set. My only criticism w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Waterproof Phone Pouch</td>\n",
       "      <td>I loved the waterproof sac, although the openi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Luxury Air Mattress</td>\n",
       "      <td>This mattress had a small hole in the top of i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pillows Insert</td>\n",
       "      <td>This is the best throw pillow fillers on Amazo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Milk Frother Handheld\\n</td>\n",
       "      <td>I loved this product. But they only seem to l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Product                                             Review\n",
       "0     Queen Size Sheet Set  I ordered a king size set. My only criticism w...\n",
       "1   Waterproof Phone Pouch  I loved the waterproof sac, although the openi...\n",
       "2      Luxury Air Mattress  This mattress had a small hole in the top of i...\n",
       "3           Pillows Insert  This is the best throw pillow fillers on Amazo...\n",
       "4  Milk Frother Handheld\\n   I loved this product. But they only seem to l..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d78f8b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Je trouve le goût médiocre. La mousse ne tient pas, c'est bizarre. J'achète les mêmes dans le commerce et le goût est bien meilleur...\\nVieux lot ou contrefaçon !?\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Review[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b940ce7c",
   "metadata": {},
   "source": [
    "## LLM Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e92dff22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<semantic_kernel.kernel.Kernel at 0x147f08d50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import semantic_kernel as sk\n",
    "import os\n",
    "import logging\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "# Demonstrate some basic logging to debug the chain\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logger = logging.getLogger('__name__')\n",
    "kernel=sk.Kernel(log=logger)\n",
    "api_key = os.environ['OPENAI_API_KEY']\n",
    "kernel.add_chat_service(\n",
    "        \"chat-gpt\", OpenAIChatCompletion(\"gpt-3.5-turbo\", api_key)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdcdb42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What is the best name to describe \\\n",
    "    a company that makes {{ $input }} ?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f1299f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a semantic function based on prompt to name a company based on product it makes. \n",
    "# Make it creative by setting a high temperature for the LLM\n",
    "productnamer = kernel.create_semantic_function(prompt, temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad44d1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some potential names to describe a company that makes Queen Size Sheet Sets could include:\n",
      "\n",
      "1. \"Royal Rest Linens\"\n",
      "2. \"Queen Comfort Co.\"\n",
      "3. \"Regal Bedding Solutions\"\n",
      "4. \"Sleepy Monarch Linens\"\n",
      "5. \"Crown Jewel Sheets\"\n",
      "6. \"Majestic Dreams Bedding\"\n",
      "7. \"Imperial Sleep Essentials\"\n",
      "8. \"Quintessential Queen Linens\"\n",
      "9. \"Palatial Bedding Collections\"\n",
      "10. \"Supreme Queen Beddings\"\n"
     ]
    }
   ],
   "source": [
    "product = \"Queen Size Sheet Set\"\n",
    "answer = await kernel.run_async(productnamer, input_str=product)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b03469",
   "metadata": {},
   "source": [
    "## SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f31aa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets chain two skills together sequerntially with output of first passed as input to second prompt\n",
    "# prompt template 1\n",
    "first_prompt = \"What is the best name to describe \\\n",
    "    a company that makes {{ $input }}?\"\n",
    "\n",
    "# Semantic Function 1\n",
    "func_one = kernel.create_semantic_function(first_prompt, temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f5d5b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prompt template 2\n",
    "second_prompt = \"Write a 20 words description for the following \\\n",
    "    company:{{ $input }}\"\n",
    "\n",
    "# chain 2\n",
    "func_two = kernel.create_semantic_function(second_prompt, temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c1eb2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Royal Sleep Company provides luxurious and comfortable sleep solutions with high-quality mattresses and bedding for a restful night's sleep.\n"
     ]
    }
   ],
   "source": [
    "answer = await kernel.run_async(func_one, func_two, input_str=\"Queen Size Sheet Set\")\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5ce18c",
   "metadata": {},
   "source": [
    "## Sequential Chain\n",
    "\n",
    "Next we will look at more flexible ways to chain together semantic functions beyond a sequential pipeline. Here you need to save output of a step into context variables using Semantic Kernel's **Native Functions** which are registered as semantic functions. Currently you need to call these native semantic functions after an LLM function to store output to a specific context variable so it can be used in latter LLM functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51b04f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.skill_definition import sk_function\n",
    "from semantic_kernel.skill_definition import sk_function, sk_function_context_parameter\n",
    "from semantic_kernel import SKContext\n",
    "\n",
    "class CopyContext:\n",
    "    \"\"\"\n",
    "    Description: Copies context to do chaining\n",
    "    \"\"\"\n",
    "\n",
    "    @sk_function(\n",
    "        description=\"Copies input to another context variable\"\n",
    "    )\n",
    "    @sk_function_context_parameter(name=\"English_Review\", description=\"Review in English.\")\n",
    "    def EnglishReview(self, context: SKContext) -> str:\n",
    "        context[\"English_Review\"] = context[\"input\"]\n",
    "        return context[\"input\"]\n",
    "\n",
    "\n",
    "    @sk_function(\n",
    "        description=\"Copies input to another context variable\"\n",
    "    )\n",
    "    @sk_function_context_parameter(name=\"summary\", description=\"Review in English.\")\n",
    "    def Summary(self, context: SKContext) -> str:\n",
    "        context[\"summary\"] = context[\"input\"]\n",
    "        return context[\"input\"]\n",
    "    \n",
    "    @sk_function(\n",
    "        description=\"Copies input to another context variable\"\n",
    "    )\n",
    "    @sk_function_context_parameter(name=\"language\", description=\"Review in English.\")\n",
    "    def Language(self, context: SKContext) -> str:\n",
    "        context[\"language\"] = context[\"input\"]\n",
    "        return context[\"input\"]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8eaa9368",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_context_skill = kernel.import_skill(CopyContext())\n",
    "v_englishreview = copy_context_skill[\"EnglishReview\"]\n",
    "v_language = copy_context_skill[\"Language\"]\n",
    "v_summary = copy_context_skill[\"Summary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "661a0820",
   "metadata": {},
   "outputs": [],
   "source": [
    "review=df.Review[5]\n",
    "context_variables = sk.ContextVariables()\n",
    "context_variables[\"review\"] = review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6770fd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 1: translate to english\n",
    "first_prompt = \"\"\"Translate the following review to english:\n",
    "    {{ $review }}\"\"\"\n",
    "\n",
    "# chain 1: input= Review and output= English_Review\n",
    "# Semantic Function 1\n",
    "func_one = kernel.create_semantic_function(first_prompt, temperature=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d85b363",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_prompt = \"\"\"Can you summarize the following review in 1 sentence:\n",
    "    {{ $English_Review }}\"\"\"\n",
    "\n",
    "# chain 2: input= English_Review and output= summary\n",
    "func_two = kernel.create_semantic_function(second_prompt, temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad2f0570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reviewer believes the taste of the product is average, with disappointing foam quality, and suspects a potential issue with the batch or its authenticity.\n"
     ]
    }
   ],
   "source": [
    "# Lets try to first chain two functions before trying a more complex chain\n",
    "# Chain looks like this: func_one-> store output in context -> func_two\n",
    "answer = await kernel.run_async(func_one, v_englishreview,func_two, input_vars=context_variables)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64a223a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets chain more functions together in more flexible manner\n",
    "# prompt template 3: translate to english\n",
    "third_prompt = \"What language is the following review:\\n\\n{{ $review }}\"\n",
    "\n",
    "# chain 3: input= Review and output= language\n",
    "func_three = kernel.create_semantic_function(third_prompt, temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7137b965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 4: follow up message\n",
    "fourth_prompt = \"\"\"Write a follow up response to the following \n",
    "    summary in the specified language:\n",
    "    Summary: {{ $summary }}\\n\\nLanguage: {{ $language }}\"\"\"\n",
    "\n",
    "# chain 4: input= summary, language and output= followup_message\n",
    "func_four = kernel.create_semantic_function(fourth_prompt, temperature=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9031d4",
   "metadata": {},
   "source": [
    "Now call a more elaborate chain where output from a step is used as input not just in next step\n",
    "Chain looks like this:\n",
    "<pre>\n",
    "                                         +-----------------------------\n",
    "                                         |                            |\n",
    "                                         |                            V\n",
    " (Input)Review ----> func_one   --->  func_two  func_three  ----->  func_four\n",
    "          |                                        ^\n",
    "          |                                        |\n",
    "          +-----------------------------------------\n",
    "</pre>\n",
    "   \n",
    "Notice that after each function , we have to call a native function (like v_englighreview, v_summary, v_language) to store output in context so it can be referenced in a subsequent step. In kernel.run_async you can specify a list of functions (semantic or native function) to call which it does in sequence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d901c399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cher(e) client(e),\n",
      "\n",
      "Nous vous remercions d'avoir partagé votre avis sur notre produit. Nous sommes désolés d'apprendre que vous êtes déçu(e) par son goût, en particulier par le fait que la mousse ne tienne pas et que vous suspectiez d'avoir reçu un lot ancien ou une contrefaçon.\n",
      "\n",
      "Nous tenons à vous assurer que tous nos produits sont soigneusement contrôlés avant d'être commercialisés. Cependant, il est possible que des variations de qualité puissent se produire de temps en temps, et nous en sommes sincèrement désolés. Votre commentaire a été transmis à notre équipe responsable de la production afin qu'elle puisse enquêter sur cette situation.\n",
      "\n",
      "Nous aimerions avoir plus de détails sur votre expérience pour mieux comprendre ce qui s'est passé. Pourriez-vous nous fournir le numéro de lot ou toute autre information pertinente figurant sur l'emballage du produit ? Cela nous aiderait grandement dans notre investigation.\n",
      "\n",
      "En tant qu'entreprise soucieuse de la satisfaction de nos clients, nous nous engageons à résoudre ce problème et à vous off\n"
     ]
    }
   ],
   "source": [
    "answer = await kernel.run_async(func_one, v_englishreview,func_two, v_summary, func_three, v_language, func_four, input_vars=context_variables)\n",
    "\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
